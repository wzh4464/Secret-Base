---
toc: true
documentclass: "ctexart"
classoption: "UTF8"
---
---
zotero-key: 6NE4CQDZ
zt-attachments:
  - 8350
title:
  - "Finding structure with randomness: Probabilistic algorithms for
    constructing approximate matrix decompositions"
---
# Finding structure with randomness: Probabilistic algorithms for constructing approximate matrix decompositions
[Zotero](zotero://select/library/items/6NE4CQDZ) [attachment](<file:///Users/zihanwu/Zotero/storage/8HPJ7KN4/Halko%20et%20al.%20-%202011%20-%20Finding%20Structure%20with%20Randomness%20Probabilistic%20A.pdf>)
> [!note] Page 217
> Abstract
> ---
> 低秩矩阵逼近,比如截断奇异值分解和秩揭示QR分解,在数据分析和科学计算中起着核心作用。近期的研究表明,随机化为进行低秩矩阵逼近提供了一个强有力的工具。这些技术比经典方法更好地利用了现代计算架构,并有可能处理真正大规模的数据集。本文概述并拓展了随机算法来计算部分矩阵分解的模块化框架。这些方法使用随机采样来识别一个子空间,该子空间捕获了矩阵的大部分作用。然后输入矩阵被明确或隐式地压缩到这个子空间,并对压缩后的矩阵进行确定性操作以获得所需的低秩因子分解。在许多情况下,这种方法在精度、鲁棒性和/或速度方面胜过其经典竞争对手。通过广泛的数值实验和详细的误差分析支持了这些论断。随机技术的具体益处取决于计算环境。考虑找到一个m x n矩阵的k个主要分量奇异值分解的模型问题。 (i) 对于密集输入矩阵,随机算法需要O(mn log(k))次浮点运算,而经典算法需要O(mnk)次。 (ii) 对于稀疏输入矩阵,浮点计数与经典克里洛夫子空间方法相匹配,但随机方法更稳健,并且可以轻松重组以利用多处理器架构。 (iii) 对于太大而无法装入快速内存的矩阵,随机技术只需要通过数据的固定次数,而经典算法需要O(k)次传递。事实上,有时可以用一次通过数据执行矩阵逼近。
> ^67YJWK2Ja8HPJ7KN4p1
> [!note] Page 220
> Overview
> ---
> 在影响20世纪科学与工程实践的“顶尖10大算法”著名榜单中,我们发现一个其实不是算法的条目:使用矩阵分解来完成数值线性代数中的基本任务的想法。在相关的文章[128]中,Stewart解释说,矩阵计算的分解方法背后的基本原则不是矩阵算法专家解决特定问题的责任,而是构建不同问题都可以从中解决的计算平台。Stewart进一步认为,这一观点产生了许多有益的后果,包括开发稳健的软件以高精度和可证明正确的方式执行这些分解。矩阵计算的分解方法仍然基础性,但是计算机硬件的发展和信息科学新应用的出现,在许多情况下使经典算法不足以胜任这一任务:现代应用的一个显著特点,特别是在数据挖掘中,是矩阵规模巨大。经典算法不一定很适合解决现在出现的这类大规模问题。在信息科学中,数据缺失或不准确很常见。经典算法设计用于产生高精度的矩阵分解,但当数据的不精确性天生限制了输出的分辨率时,花费额外的计算资源似乎很奢侈。数据传输现在在数值算法的计算成本中起着重要作用。即使需要进行同样多或更多的浮点运算,在实践中需要更少的数据传输的技术可能会快得多。随着计算机硬件架构持续发展,数值算法适应各种新型架构(如图形处理单元)变得越来越重要。本文的目的是论述随机化算法为构建近似矩阵分解提供了强大的工具。这些技术简单高效,有时效果令人印象深刻。与标准的确定性算法相比,随机方法通常更快,并且(也许令人惊讶地)更稳健。此外,它们可以产生任意指定公差以上的精确因子分解,这使得用户可以在需要时用精度换速度。我们提供了数值证据表明这些算法可以成功地解决真实的计算问题。简而言之,我们的目标是展示随机方法如何与经典技术相结合,产生有详细理论保证的高效现代算法。我们特别努力帮助从业者识别随机技术可能胜过既定方法的情况。在本文中,我们详细引用了关于使用随机技术计算低秩近似的前人工作。
> ^WR8WUXUBa8HPJ7KN4p4
> [!note] Page 221
> 1.1. Approximation by Low-Rank Matrices.
> ---
> 1.1 低秩矩阵近似标准矩阵分解方法包括奇异值分解(SVD)、特征值分解以及列交换QR分解,所有这些方法都揭示了一个矩阵的(数值)秩。这些分解方法的截断版本通常被用来表达一个给定矩阵的低秩近似:A ≈ B C, A ≈ B C，其中A是一个m x n矩阵,B是一个m x k矩阵,C是一个k x n矩阵。内部维度k有时被称为矩阵的数值秩。当数值秩远小于m和n时,像(1.1)这样的分解允许低成本存储矩阵并与向量或其他矩阵快速相乘。这些分解也可以被用于数据解释或求解计算问题,如最小二乘法。数值秩低的矩阵在各种科学应用中广泛出现。我们只列出几个例子:统计和数据挖掘中的一种基本方法是通过对数据矩阵执行主成分分析(PCA)来计算向量值数据中的最大方差方向。PCA就是一个低秩矩阵近似。数据分析中的另一种标准技术是基于假设自由度少于环境维数的假设对数据进行低维嵌入。在许多情况下,该方法简化为计算从数据导出的矩阵的部分奇异值分解。通过最小二乘法拟合从测量数据估计参数通常导致非常大的线性方程组,这些方程组接近线性相关。有效的系数矩阵分解技术导致了求解最小二乘问题的有效技术。许多用于快速求解偏微分方程以及快速评估势场的快速算法,如快速多极子方法和H矩阵,都依赖于连续算子的低秩近似。具有快速振荡系数的多尺度物理现象的建模通常涉及偏微分方程。这种环境下的模型还原或粗化技术通常基于这样的观察,即将输入数据映射到所需输出数据的线性变换可以通过一个低秩算子来近似。
> ^SUD8H2E7a8HPJ7KN4p5
> [!note] Page 221
> 1.2. Matrix Approximation Framework
> ---
> 1.2 矩阵近似框架
> 
> 计算给定矩阵的低秩近似可以自然地分为两个计算阶段。第一个是构建一个能够捕获矩阵运算的低维子空间。第二个是限制矩阵到子空间,然后计算约简矩阵的标准分解(QR、SVD等)。稍微正式一点,我们将计算细分如下:
> 
> 阶段A:计算输入矩阵A的范围的近似基。换句话说,我们需要一个矩阵Q,满足:
> 
> Q的列正交归一化,并且 A≈QQ^*A。
> 
> 我们希望基矩阵Q包含尽可能少的列,但更重要的是对输入矩阵有一个准确的近似。
> 
> 阶段B:给定满足(1.2)的矩阵Q,我们使用Q来帮助计算A的标准分解(QR、SVD等)。
> 
> 阶段A中的任务可以用随机采样方法非常有效地执行,这些方法是本文的主要研究对象。在下一小节中,我们概述了这些想法。本文的主体部分提供了算法细节(第4节)和它们性能的理论分析(第8-11节)。阶段B可以用经典的确定性方法完成。第3.3.3节简要介绍了这些技术,第5节展示了我们如何应用它们产生低秩分解。
> 
> 在目前的发展阶段,Q的输出如何帮助我们在阶段B中的工作可能还不清楚。让我们通过描述如何在给定满足(1.2)的Q矩阵的情况下得到A的近似SVD来说明。更准确地说,我们希望计算具有正交列的U和V以及非负对角矩阵Σ,使得A≈UΣV^*。 在三个简单步骤之后可以达到这个目标:
> 
> 1. 形成 B=Q^*A,得到低秩分解 A≈QB。
> 
> 2. 计算小矩阵的SVD:B= ̃UΣV^*。
> 
> 3. 设置U=Q ̃U。
> 
> 当Q具有很少的列时,这个过程是有效的,因为我们可以容易地构造约简矩阵B并快速计算其SVD。在实践中,我们通常可以通过更精细的技术避免显式形成B。在某些情况下,阶段B中甚至不必重新访问输入矩阵A。这一观察使我们能够开发单遍算法,这些算法只访问A的每个条目一次。类似的操作可以容易地产生其他标准分解,例如列交换QR分解、特征值分解等。
> ^QGNEGUPUa8HPJ7KN4p5
> [!note] Page 223
> 1.3.2. Intuition
> ---
> 1.3.2 原理说明为了理解随机性如何帮助我们解决固定秩问题,考虑一些启发性实例是很有帮助的。首先,假设我们正在寻求一个秩为k的矩阵A的范围基。绘制一个随机向量ω,并形成y = Aω。目前随机向量的精确分布不重要;只需将y视为从A的范围中随机采样。我们重复此采样过程k次:y(i) = Aω(i), i = 1,2,...,k。
> y(i) = Aω(i), i = 1,2,...,k。由于随机性,随机向量集合{ω(i): i = 1,2,...,k}很可能是一般线性位置。特别是,随机向量形成一个线性无关组,没有线性组合落在A的零空间中。因此,样本向量集合{y(i): i = 1,2,...,k}也线性无关,因此跨越了A的范围。因此,为了产生A范围的正交归一化基,我们只需要正交归一化样本向量。现在,假设A = B + E,其中B是一个包含我们寻求信息的秩为k的矩阵,E是一个小扰动。我们的优先任务是获得一个尽可能覆盖B范围的基础,而不是最小化基向量的数量。因此,我们固定一个小数p,并生成k + p个样本:y(i) = Aω(i) = Bω(i) + Eω(i), i = 1,2,...,k+p。
> y(i) = Aω(i) = Bω(i) + Eω(i), i = 1,2,...,k+p。扰动E将每个样本向量的方向移出B的范围之外,这可以阻止{y(i): i = 1,2,...,k}的跨度覆盖B的整个范围。相比之下,增丰样本集合{y(i): i = 1,2,...,k+p}更有可能跨越所需的子空间。我们需要多少额外的样本呢?令人惊讶的是,对于某些类型的随机采样方案,失败概率随着超采样参数p以超指数级减小;参见(1.9)。从实用的角度来看,设置p = 5或p = 10通常可以取得超级结果。这一观察是支持随机数值线性代数方法的主要事实之一。
> ^GTZR75YKa8HPJ7KN4p7
> [!note] Page 224
> 1.3.3. A Prototype Algorithm.
> ---
> 1.3.3 原型算法
> 
> 第1.3.2节中的直观方法可以应用于一般矩阵。暂时省略计算细节,我们在标记为“原型算法”的图中正式化该过程。这个简单的算法绝不是新算法。它本质上是具有随机初始子空间的子空间迭代的第一步[61, sect. 7.3.2]。新颖之处在于额外的观察结果,即初始子空间的维度应略高于我们试图逼近的不变子空间。有了这个修改,通常不需要进一步迭代就可以获得高质量的(1.5)解。我们认为这个想法可以追溯到[92,106,119]。 为了有信心调用原型算法,我们必须解决几个实际和理论问题:
> 
> - 我们应该使用什么随机矩阵Ω?我们需要多少超采样?
> 
> - 矩阵Y可能病态。我们如何正交化其列以形成矩阵Q?
> 
> - 计算成本是多少?
> 
> - 当矩阵的数值秩预先未知时,我们如何解决固定精度问题(1.3)?
> 
> - 我们如何使用基Q来计算其他矩阵分解?
> 
> - 随机方法适用于实际问题吗?其速度/精度/稳健性与标准技术相比如何?
> 
> - 我们可以期待什么误差界?以何种概率?
> 
> 接下来的几节总结了这些问题的答案。我们描述了几个问题场景,原型算法可以在其中有效实现,并提出了描述最重要具体化性能的定理。最后,我们详细阐述了如何将这些想法应用于逼近大数据矩阵的截断SVD。本文的其余部分包含更全面的处理,包括伪代码、数值实验和详细的理论。
> ^2NIN2AY4a8HPJ7KN4p8
> [!note] Page 227
> 1.6. Example: Randomized SVD
> ^7EQUHB84a8HPJ7KN4p11
> [!note] Page 236
> 3.2.1. The Pivoted QR Factorization.
> ^GIFDVCIZa8HPJ7KN4p20
